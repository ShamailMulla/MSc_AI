{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#@title ## Coursework: Train GPT2 & Generate samples"
      ],
      "metadata": {
        "id": "QE-DOtX22sga",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from IPython.display import clear_output\n",
        "import ipywidgets\n",
        "\n",
        "from google.colab import drive, files\n",
        "drive.mount('/content/drive/', force_remount=True)"
      ],
      "metadata": {
        "id": "4LsWPqx-WB7H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get library requirements and supporting files from google drive\n",
        "drive_path = '/content/drive/My Drive/MSc/Sem2_CC/'\n",
        "os.chdir(drive_path)"
      ],
      "metadata": {
        "id": "Q-TwyU_eRGry"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  import gpt_2_simple as gpt2\n",
        "except Exception as e:\n",
        "  # if this is running the first time then download required libraries\n",
        "  print(e)\n",
        "  !pip install -r requirements.txt\n",
        "  import gpt_2_simple as gpt2\n",
        "\n",
        "  #Â There is a bug in jax, so uninstall this\n",
        "  !pip uninstall -y jax jaxlib\n",
        "  !pip install diffusers==0.11.1\n",
        "  gpt2.download_gpt2(model_name=\"124M\")\n",
        "\n",
        "  clear_output()"
      ],
      "metadata": {
        "id": "Od9xxtnnV-JN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "import gensim\n",
        "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
        "from nltk.tokenize import word_tokenize\n",
        "from gensim.models.doc2vec import Doc2Vec"
      ],
      "metadata": {
        "id": "Ps7FDJ6Vderw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BcWiEWpx2KlA"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "tf.config.list_physical_devices()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dir_ = 'train_content/'"
      ],
      "metadata": {
        "id": "qc1MLNjY4Jot"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import helper_functions as help_"
      ],
      "metadata": {
        "id": "oDJBQCGa4NbU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting all the content and tagging it for learning semantic embeddings\n",
        "content = []\n",
        "for f in os.listdir(dir_):\n",
        "    path = dir_ + f\n",
        "    text = open(path,'r').read().replace('\\n','')\n",
        "    content.append(text)\n",
        "documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(content)]\n",
        "#\n",
        "model = Doc2Vec(vector_size=100,\n",
        "                min_count=3, epochs=20)\n",
        "model.build_vocab(documents)\n",
        "model.train(documents, total_examples=model.corpus_count, epochs=80)\n",
        "model.save(\"doc2vec_model.model\")\n",
        "\n",
        "document_vectors = [model.infer_vector(\n",
        "                        word_tokenize(doc.lower())\n",
        "                    )\n",
        "                    for doc in content]\n",
        "\n",
        "document_vectors = np.array(document_vectors)\n",
        "avg_embeddings = np.average(document_vectors,axis=0)\n",
        "np.save('avg_corpus_embeddings.npy', avg_embeddings)"
      ],
      "metadata": {
        "id": "MK95hAmUb8py"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf_session1 = gpt2.start_tf_sess()\n",
        "gpt2.finetune(tf_session1, dataset=dir_, model_name='124M', steps=500,\n",
        "              restore_from='latest', run_name='run1',\n",
        "              checkpoint_dir='checkpoint/', batch_size=1,\n",
        "              sample_length=128, print_every=10, sample_every=100, save_every=50\n",
        "              )\n",
        "gpt2.copy_checkpoint_to_gdrive(copy_folder=drive_path)"
      ],
      "metadata": {
        "id": "VA20m0DCTJe0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('avg_corpus_embeddings.npy', 'rb') as f:\n",
        "    avg_embeddings = np.load(f)\n",
        "\n",
        "model = Doc2Vec.load('doc2vec_model.model')"
      ],
      "metadata": {
        "id": "5-JWSX_hjNFM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.compat.v1.reset_default_graph()\n",
        "session0 = gpt2.start_tf_sess()\n",
        "gpt2.load_gpt2(session0, checkpoint='model-500')"
      ],
      "metadata": {
        "id": "N2AEXZQIp8N4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gpt2.generate(session0, run_name='run1',\n",
        "              prefix='<|startoftext|>',\n",
        "              destination_path='story_samples.txt',\n",
        "              nsamples=10,\n",
        "              top_k=20, include_prefix=False\n",
        "            )"
      ],
      "metadata": {
        "id": "3DRdpU_B1ooE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}